{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yzm9393/swineBRET-ICD/blob/main/01_Data_Preparation_for_Annotation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2d261e8-0abc-494c-b31a-e2aa0c44b72d",
      "metadata": {
        "id": "d2d261e8-0abc-494c-b31a-e2aa0c44b72d"
      },
      "source": [
        "## 1. Import relevant libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import re\n",
        "import time\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "pvSTSyKZsSxk"
      },
      "id": "pvSTSyKZsSxk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Define file paths"
      ],
      "metadata": {
        "id": "4QgtWALOsha0"
      },
      "id": "4QgtWALOsha0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e76cc470-ee59-43f4-9d9b-a7e50554d4ab",
      "metadata": {
        "id": "e76cc470-ee59-43f4-9d9b-a7e50554d4ab",
        "outputId": "059448c8-f65f-4258-a46b-9591a4e60dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING *** file size (12732397) not 512 + multiple of sector size (512)\n"
          ]
        }
      ],
      "source": [
        "# --- File Paths & Naming ---\n",
        "df = pd.read_excel(\"/Users/zimoyang/Documents/swine_project/data/HistoryData.xls\")\n",
        "TEXT_COLUMN = \"HISTORY\"\n",
        "ID_COLUMN = \"U_SUBMISSIONID\"\n",
        "DATE_COLUMN = \"CREATEDT\"\n",
        "ANNOTATION_FILE_OUTPUT = 'Enriched_Annotation_Sample_For_Dr_Poljak.xlsx'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Define configurations for anoynmizations"
      ],
      "metadata": {
        "id": "Xdr-nyIhskqB"
      },
      "id": "Xdr-nyIhskqB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24fd9b04-9fe1-4dca-9468-61e8de805596",
      "metadata": {
        "id": "24fd9b04-9fe1-4dca-9468-61e8de805596"
      },
      "outputs": [],
      "source": [
        "# --- Parameters ---\n",
        "TEST_SET_FRACTION = 0.20\n",
        "ANNOTATION_SAMPLE_SIZE = 2000\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# Configuration\n",
        "NLP_MODEL_NAME = \"en_core_web_md\"\n",
        "\n",
        "# Rule-based classification\n",
        "UNKNOWN_EXACT_MATCH_RULES = [\n",
        "    \"no history provided\", \"no history given\", \"none given\", \"none\", \"unknown\"\n",
        "]\n",
        "DIAGNOSTIC_EXACT_MATCH_RULES = [\n",
        "    \"test purpose monitoring\", \"monitoring\", \"routine monitoring\", \"testing for olymel\", \"testing for maple leaf\", \"vaccination\",\n",
        "    \"vaccine\", \"testing\", \"pcr\", \"healthy\", \"normal\", \"booster\", \"surveillance\", \"vax\", \"health check\", \"blood test\"\n",
        "]\n",
        "# Anonymization regex patterns\n",
        "ANONYMIZATION_PATTERNS_REGEX = {\n",
        "    \"company\": re.compile(r'\\b(olymel|maple leaf|duroc|conestoga|hypor)\\b', re.IGNORECASE), # For ORG_NAME\n",
        "    # Optional: Keep these if you want regex to catch specific date/ID formats BEFORE spaCy.\n",
        "    # If spaCy alone should handle dates (with stricter logic), you can comment these out.\n",
        "    \"date\": re.compile(r'\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\.?\\s+\\d{1,2},?\\s+\\d{4}\\b', re.IGNORECASE),\n",
        "    \"iso_date\": re.compile(r'\\b\\d{4}-\\d{2}-\\d{2}\\b'),\n",
        "    \"submission_id\": re.compile(r'\\b[A-Z]{2}\\d{3,6}\\b'), # Example, adjust as needed\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Define anonymization functions"
      ],
      "metadata": {
        "id": "cXQ9s1b6sxcZ"
      },
      "id": "cXQ9s1b6sxcZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c4933f9-0be1-48d3-bf25-9fd006506a53",
      "metadata": {
        "id": "6c4933f9-0be1-48d3-bf25-9fd006506a53"
      },
      "outputs": [],
      "source": [
        "# Function Definitions\n",
        "\n",
        "def load_nlp_model(model_name=NLP_MODEL_NAME):\n",
        "    \"\"\"Loads and returns the spaCy NLP model.\"\"\"\n",
        "    try:\n",
        "        nlp = spacy.load(model_name)\n",
        "        print(f\"Successfully loaded spaCy model: {model_name}\")\n",
        "        return nlp\n",
        "    except OSError:\n",
        "        print(f\"spaCy model '{model_name}' not found. Please download it: python -m spacy download {model_name}\")\n",
        "        return None\n",
        "\n",
        "def clean_text_data(text):\n",
        "    \"\"\"Cleans a single text string.\"\"\"\n",
        "    text = str(text).strip().lower()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[\\r\\n]+', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s_]', '', text) # Keeps alphanumeric, whitespace, underscore\n",
        "    return text\n",
        "\n",
        "def classify_text_by_rules(text_input,\n",
        "                           unknown_exact_match,\n",
        "                           diagnostic_exact_match): # Only two rule lists now\n",
        "    \"\"\"\n",
        "    Classifies cleaned text based on predefined, simplified exact match rules.\n",
        "    \"\"\"\n",
        "    text = str(text_input).strip().lower() # Rules expect cleaned, lowercased text\n",
        "\n",
        "    if text in unknown_exact_match:\n",
        "        return \"unknown_rule\"\n",
        "    elif text in diagnostic_exact_match:\n",
        "        return \"diagnostic_rule\"\n",
        "\n",
        "    # Everything else is initially considered \"Normal\"\n",
        "    return \"normal_rule\"\n",
        "\n",
        "def anonymize_single_text(text_input, nlp_model, regex_patterns):\n",
        "    \"\"\"\n",
        "    Anonymizes text with very strict date handling:\n",
        "    - Regex for specific \"company\" patterns ([ORG_NAME]).\n",
        "    - Regex for specific, full date formats (\"Month Day, Year\", \"YYYY-MM-DD\").\n",
        "    - SpaCy NER for:\n",
        "        - PERSON: Replaced with [VET_NAME] only if \"Dr.\" prefix is found.\n",
        "        - GPE, LOC: Replaced with [LOCATION] (with exceptions).\n",
        "        - DATE: Replaced with [DATE] ONLY if it's a regex match OR if spaCy's entity\n",
        "                  clearly contains year & day components and is not a duration.\n",
        "    - SpaCy NER for ORG/FAC is IGNORED for replacement.\n",
        "    - EntityRuler \"protected_labels\" are preserved.\n",
        "    \"\"\"\n",
        "    text = str(text_input)\n",
        "\n",
        "    # 1. Apply defined regex patterns first\n",
        "    # These handle your explicit, high-confidence patterns.\n",
        "    text_after_regex = text # Store the result of regex processing\n",
        "    if \"company\" in regex_patterns:\n",
        "        text_after_regex = regex_patterns[\"company\"].sub(\"[ORG_NAME]\", text_after_regex)\n",
        "    if \"date\" in regex_patterns: # Your regex for \"Month Day, Year\" etc.\n",
        "        text_after_regex = regex_patterns[\"date\"].sub(\"[DATE]\", text_after_regex)\n",
        "    if \"iso_date\" in regex_patterns: # Your regex for \"YYYY-MM-DD\"\n",
        "        text_after_regex = regex_patterns[\"iso_date\"].sub(\"[DATE]\", text_after_regex)\n",
        "    if \"submission_id\" in regex_patterns:\n",
        "        text_after_regex = regex_patterns[\"submission_id\"].sub(\"[SUBMISSION_ID]\", text_after_regex)\n",
        "\n",
        "    text = text_after_regex # Update text with results of regex pass\n",
        "\n",
        "    if nlp_model is None:\n",
        "        return text\n",
        "\n",
        "    doc = nlp_model(text)\n",
        "    new_text_parts = []\n",
        "    current_pos = 0\n",
        "\n",
        "    protected_labels_from_ruler = [\n",
        "        \"DISEASE_CODE\", \"VET_ABBREV\", \"MATERIAL\", \"ANIMAL_GROUP_TERM\",\n",
        "        \"INTERNAL_CODE\", \"PROCESS_TERM\", \"BIOLOGICAL_SAMPLE\"\n",
        "    ]\n",
        "    known_non_person_terms = [\n",
        "        \"prrs\", \"routine prrs\", \"rmgp3\", \"s\", \"pcr coronavirus s\",\n",
        "        \"pedv\", \"routine pedv\", \"gilt iso\", \"bloodserum\", \"dacron\"\n",
        "    ]\n",
        "    known_non_location_terms = [\"viro\"]\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        new_text_parts.append(text[current_pos:ent.start_char])\n",
        "        placeholder = ent.text\n",
        "        ent_text_lower = ent.text.lower()\n",
        "\n",
        "        if ent.label_ in protected_labels_from_ruler:\n",
        "            placeholder = ent.text\n",
        "        elif ent.label_ == \"PERSON\":\n",
        "            if ent_text_lower in known_non_person_terms:\n",
        "                placeholder = ent.text\n",
        "            else:\n",
        "                is_doctor_prefix = False\n",
        "                if re.match(r'^(dr\\.?|doctor)\\s+', ent.text, re.IGNORECASE):\n",
        "                    is_doctor_prefix = True\n",
        "                else:\n",
        "                    prefix_window_start = max(0, ent.start_char - 10)\n",
        "                    text_segment_before = text[prefix_window_start:ent.start_char]\n",
        "                    if re.search(r'(dr\\.?|doctor)\\s+$', text_segment_before, re.IGNORECASE):\n",
        "                        is_doctor_prefix = True\n",
        "                if is_doctor_prefix:\n",
        "                    placeholder = \"[VET_NAME]\"\n",
        "                else:\n",
        "                    placeholder = ent.text\n",
        "        elif ent.label_ in (\"GPE\", \"LOC\"):\n",
        "            if ent_text_lower in known_non_location_terms:\n",
        "                placeholder = ent.text\n",
        "            elif ent_text_lower != \"[location]\":\n",
        "                placeholder = \"[LOCATION]\"\n",
        "\n",
        "        elif ent.label_ == \"DATE\":\n",
        "            if ent.text == \"[DATE]\": # Already handled by your regex pass\n",
        "                placeholder = \"[DATE]\"\n",
        "            else: # For DATE entities found by spaCy that weren't caught by your initial regex\n",
        "                # Apply your stricter conditions (e.g., contains letters or multiple numbers, not a duration)\n",
        "                if re.fullmatch(r'\\d+\\s+(week|day|month|year)s?(\\s+old)?', ent_text_lower): # Exclude durations\n",
        "                    placeholder = ent.text\n",
        "                else:\n",
        "                    has_year_4_digits = bool(re.search(r'\\b\\d{4}\\b', ent.text))\n",
        "                    has_day_number = bool(re.search(r'\\b\\d{1,2}\\b', ent.text))\n",
        "                    has_month_name = bool(re.search(r'(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)', ent_text_lower))\n",
        "                    is_structured_date_like = bool(re.fullmatch(r'\\d{4}[\\-\\/\\.]\\d{1,2}[\\-\\/\\.]\\d{1,2}', ent.text)) or \\\n",
        "                                              bool(re.fullmatch(r'\\d{1,2}[\\-\\/\\.]\\d{1,2}[\\-\\/\\.]\\d{4}', ent.text))\n",
        "\n",
        "                    if is_structured_date_like or \\\n",
        "                       (has_year_4_digits and has_day_number) or \\\n",
        "                       (has_month_name and has_day_number):\n",
        "                        placeholder = \"[DATE]\"\n",
        "                    # else: placeholder remains ent.text\n",
        "        new_text_parts.append(placeholder)\n",
        "        current_pos = ent.end_char\n",
        "    new_text_parts.append(text[current_pos:])\n",
        "    return \"\".join(new_text_parts)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Define preprocessing pipeline"
      ],
      "metadata": {
        "id": "rjauJQ1hwu9l"
      },
      "id": "rjauJQ1hwu9l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d8ab7b0-1618-4442-8ce8-9faff6c24fcd",
      "metadata": {
        "id": "9d8ab7b0-1618-4442-8ce8-9faff6c24fcd"
      },
      "outputs": [],
      "source": [
        "# More functions\n",
        "def run_preprocessing_pipeline(df, text_column, nlp_model):\n",
        "    if nlp_model is None:\n",
        "        print(\"Error: NLP model not loaded. Cannot run preprocessing pipeline.\")\n",
        "        # Add placeholder columns to avoid breaking downstream if possible\n",
        "        df['cleaned_text'] = \"\"\n",
        "        df['rule_based_note_type'] = \"error_nlp_missing\"\n",
        "        df['anonymized_text_for_ml'] = \"\"\n",
        "        df['target_ml_diagnostic'] = 0\n",
        "        df['target_ml_unknown'] = 0\n",
        "        df['is_normal_for_icd'] = False\n",
        "        return df\n",
        "\n",
        "    print(\"Starting preprocessing pipeline...\")\n",
        "\n",
        "    # Step 1: Clean Text\n",
        "    print(f\"Cleaning text in column '{text_column}' for {len(df)} records...\")\n",
        "    df['cleaned_text'] = df[text_column].progress_apply(clean_text_data)\n",
        "\n",
        "    # Step 2: Apply Rule-Based Classification (uses cleaned_text - SIMPLIFIED CALL)\n",
        "    print(\"Applying simplified rule-based classification...\")\n",
        "    # (UNKNOWN_EXACT_MATCH_RULES, DIAGNOSTIC_EXACT_MATCH_RULES) are defined from Cell 2 & 3\n",
        "    df['rule_based_note_type'] = df['cleaned_text'].progress_apply(\n",
        "        lambda x: classify_text_by_rules(x,\n",
        "                                         UNKNOWN_EXACT_MATCH_RULES,\n",
        "                                         DIAGNOSTIC_EXACT_MATCH_RULES)\n",
        "    )\n",
        "\n",
        "    # Step 3: Anonymize Text (uses cleaned_text to produce a separate anonymized version for ML)\n",
        "    print(\"Anonymizing text for ML...\")\n",
        "    # Ensure anonymize_single_text and ANONYMIZATION_PATTERNS_REGEX are defined from Cell 2 & 3\n",
        "    # THIS IS THE CRUCIAL LINE FOR CREATING THE COLUMN:\n",
        "    df['anonymized_text_for_ml'] = df['cleaned_text'].progress_apply(\n",
        "        lambda x: anonymize_single_text(x, nlp_model, ANONYMIZATION_PATTERNS_REGEX)\n",
        "    )\n",
        "\n",
        "    # Step 4: Prepare target labels for \"Diagnostic\" and \"Unknown\" ML Classifiers\n",
        "    print(\"Preparing target labels for auxiliary ML classifiers...\")\n",
        "    df['target_ml_diagnostic'] = (df['rule_based_note_type'] == 'diagnostic_rule').astype(int)\n",
        "    df['target_ml_unknown'] = (df['rule_based_note_type'] == 'unknown_rule').astype(int)\n",
        "\n",
        "    # Step 5: Flag \"normal\" text intended for ICD-11 classifiers\n",
        "    df['is_normal_for_icd'] = (df['rule_based_note_type'] == 'normal_rule')\n",
        "\n",
        "    print(\"Preprocessing pipeline completed.\")\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Prepare the 2000 data set for Dr.Poljak to annotate\n",
        "1. Loading and Cleaning:It loads the full dataset and removes records with no text.\n",
        "\n",
        "2. Splitting Data: It separates the data into a large 80% training set and a smaller 20% test set, which is set aside for the final evaluation.\n",
        "\n",
        "3. Finding Clinical Cases: It uses keyword rules to pre-classify the training data into \"Clinical\" and \"Monitoring/Unknown\" groups.\n",
        "\n",
        "4. Creating an Enriched Sample: It creates a 2,000-record sample by taking 90% from the \"Clinical\" group and 10% from the \"Monitoring/Unknown\" group to focus the expert's time on the most relevant cases.\n",
        "\n",
        "5. Formatting and Saving: Finally, it shuffles the sample, adds empty columns for the expert's labels, and saves it as an Excel file."
      ],
      "metadata": {
        "id": "txDHDExCtKv7"
      },
      "id": "txDHDExCtKv7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e62ec5c6-818d-4f00-b42b-1f51f8b45f99",
      "metadata": {
        "id": "e62ec5c6-818d-4f00-b42b-1f51f8b45f99",
        "outputId": "276f7612-cde5-422a-b456-b47f36207209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING *** file size (12732397) not 512 + multiple of sector size (512)\n",
            "--- Starting One-Time Data Preparation ---\n",
            "\n",
            "Initial record count: 64923\n",
            "Record count after dropping records with missing 'HISTORY': 46322\n",
            "--- Performing 80/20 Random Split ---\n",
            "Training & Development Set size: 37058 records.\n",
            "Final Test Set size: 9264 records.\n",
            "\n",
            "--- Applying Rule-Based Filter to Training Set ---\n",
            "Pre-classification complete. Value counts:\n",
            "sampling_type\n",
            "Clinical      13533\n",
            "Monitoring    13368\n",
            "Unknown       10157\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Performing Targeted Sampling to Create Enriched Dataset ---\n",
            "Sampling 1800 records from the 'Clinical' pool...\n",
            "Sampling 200 records from the 'Monitoring/Healthy/Unknown' pool...\n",
            "\n",
            "Created final enriched annotation set with 2000 records.\n",
            "\n",
            "Successfully created 'Enriched_Annotation_Sample_For_Dr_Poljak.xlsx'.\n",
            "This file contains an enriched sample with a higher proportion of clinical cases.\n"
          ]
        }
      ],
      "source": [
        "#Main\n",
        "df_full = pd.read_excel(\"/Users/zimoyang/Documents/swine_project/data/HistoryData.xls\")\n",
        "ID_COLUMN = 'U_SUBMISSIONID'\n",
        "TEXT_COLUMN = 'HISTORY'\n",
        "TARGET_ANNOTATION_SIZE = 2000\n",
        "TEST_SET_FRACTION = 0.20\n",
        "DATE_COLUMN = 'CREATEDT'\n",
        "\n",
        "print(\"--- Starting One-Time Data Preparation ---\")\n",
        "\n",
        "# --- 1. Initial Cleaning ---\n",
        "# This is the critical step correctly identified was missing.\n",
        "print(f\"\\nInitial record count: {len(df_full)}\")\n",
        "# First, convert any empty strings in the text column to proper NA values\n",
        "df_full[TEXT_COLUMN] = df_full[TEXT_COLUMN].replace('', pd.NA)\n",
        "# Now, drop any rows that have NA in the text column\n",
        "df_full.dropna(subset=[TEXT_COLUMN], inplace=True)\n",
        "print(f\"Record count after dropping records with missing '{TEXT_COLUMN}': {len(df_full)}\")\n",
        "\n",
        "\n",
        "# --- 2. Perform the 80/20 Split ---\n",
        "print(\"--- Performing 80/20 Random Split ---\")\n",
        "df_test_final = df_full.sample(frac=TEST_SET_FRACTION, random_state=42)\n",
        "df_train_dev = df_full.drop(df_test_final.index)\n",
        "\n",
        "print(f\"Training & Development Set size: {len(df_train_dev)} records.\")\n",
        "print(f\"Final Test Set size: {len(df_test_final)} records.\")\n",
        "\n",
        "# --- Rule-based classification keywords ---\n",
        "UNKNOWN_EXACT_MATCH_RULES = [\n",
        "    \"no history provided\", \"no history given\", \"none given\", \"none\", \"unknown\"\n",
        "]\n",
        "MONITORING_RULES = [\n",
        "    \"test purpose monitoring\", \"monitoring\", \"routine monitoring\", \"testing for olymel\", \"testing for maple leaf\", \"vaccination\",\n",
        "    \"vaccine\", \"testing\", \"pcr\", \"healthy\", \"normal\", \"booster\", \"surveillance\", \"vax\", \"health check\", \"blood test\"\n",
        "]\n",
        "\n",
        "# --- 3. Apply Rule-Based Filter to the Training Set ---\n",
        "print(\"\\n--- Applying Rule-Based Filter to Training Set ---\")\n",
        "\n",
        "def classify_text_for_sampling(text):\n",
        "    \"\"\"Applies rules to classify text for sampling purposes.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return 'Unknown'\n",
        "\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    if text_lower in UNKNOWN_EXACT_MATCH_RULES:\n",
        "        return 'Unknown'\n",
        "\n",
        "    # Use regex to find any of the monitoring/healthy keywords\n",
        "    # This is more robust than an exact match for this list\n",
        "    if any(re.search(r'\\b' + re.escape(keyword) + r'\\b', text_lower) for keyword in MONITORING_RULES):\n",
        "        return 'Monitoring'\n",
        "\n",
        "    return 'Clinical' # If it's not Unknown or Monitoring, it's likely a clinical case\n",
        "\n",
        "# Apply the function to create a temporary classification column\n",
        "df_train_dev['sampling_type'] = df_train_dev[TEXT_COLUMN].apply(classify_text_for_sampling)\n",
        "\n",
        "print(\"Pre-classification complete. Value counts:\")\n",
        "print(df_train_dev['sampling_type'].value_counts())\n",
        "\n",
        "# --- 4. Perform Targeted, Enriched Sampling ---\n",
        "print(\"\\n--- Performing Targeted Sampling to Create Enriched Dataset ---\")\n",
        "\n",
        "# Define the desired composition of the final 2000-record set\n",
        "# We will aim for 90% clinical cases and 10% non-clinical cases\n",
        "clinical_pct = 0.90\n",
        "non_clinical_pct = 0.10\n",
        "\n",
        "num_clinical_to_sample = int(TARGET_ANNOTATION_SIZE * clinical_pct)\n",
        "num_non_clinical_to_sample = TARGET_ANNOTATION_SIZE - num_clinical_to_sample\n",
        "\n",
        "# Create pools of records\n",
        "clinical_pool = df_train_dev[df_train_dev['sampling_type'] == 'Clinical']\n",
        "non_clinical_pool = df_train_dev[df_train_dev['sampling_type'] != 'Clinical']\n",
        "\n",
        "print(f\"Sampling {num_clinical_to_sample} records from the 'Clinical' pool...\")\n",
        "clinical_sample = clinical_pool.sample(n=min(num_clinical_to_sample, len(clinical_pool)), random_state=42)\n",
        "\n",
        "print(f\"Sampling {num_non_clinical_to_sample} records from the 'Monitoring/Healthy/Unknown' pool...\")\n",
        "non_clinical_sample = non_clinical_pool.sample(n=min(num_non_clinical_to_sample, len(non_clinical_pool)), random_state=42)\n",
        "\n",
        "# Combine the samples\n",
        "annotation_sample = pd.concat([clinical_sample, non_clinical_sample])\n",
        "\n",
        "# --- 5. Prepare and Save the Final File for Dr. Poljak ---\n",
        "# Shuffle the final dataset to ensure random order for annotation\n",
        "final_annotation_df = annotation_sample.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nCreated final enriched annotation set with {len(final_annotation_df)} records.\")\n",
        "\n",
        "# Define the final ICD-11 labels for the columns\n",
        "final_icd11_labels = [\n",
        "    '[01] Certain infectious or parasitic diseases', '[02] Neoplasms',\n",
        "    '[03] Diseases of the blood or blood-forming organs', '[04] Diseases of the immune system',\n",
        "    '[05] Endocrine, nutritional or metabolic diseases', '[06] Mental, behavioural or neurodevelopmental disorders',\n",
        "    '[08] Diseases of the nervous system', '[09] Diseases of the visual system',\n",
        "    '[10] Diseases of the ear or mastoid process', '[11] Diseases of the circulatory system',\n",
        "    '[12] Diseases of the respiratory system', '[13] Diseases of the digestive system',\n",
        "    '[14] Diseases of the skin', '[15] Diseases of the musculoskeletal system or connective tissue',\n",
        "    '[16] Diseases of the genitourinary system', '[18] Pregnancy, childbirth or the puerperium',\n",
        "    '[19] Certain conditions originating in the perinatal period', '[20] Developmental anomalies',\n",
        "    '[22] Injury, poisoning or certain other consequences of external causes',\n",
        "    'Monitoring', 'Unknown'\n",
        "]\n",
        "\n",
        "columns_to_include = [ID_COLUMN, DATE_COLUMN, TEXT_COLUMN]\n",
        "df_for_annotation = annotation_sample[columns_to_include].copy().reset_index(drop=True)\n",
        "\n",
        "for label in final_icd11_labels:\n",
        "    df_for_annotation[label] = ''\n",
        "\n",
        "# Save to Excel\n",
        "output_filename_excel = 'Enriched_Annotation_Sample_For_Dr_Poljak.xlsx'\n",
        "df_for_annotation.to_excel(output_filename_excel, index=False)\n",
        "\n",
        "print(f\"\\nSuccessfully created '{output_filename_excel}'.\")\n",
        "print(\"This file contains an enriched sample with a higher proportion of clinical cases.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Prepare the 1000 test data for Dr.Poljak to annotate (same process as the 2000 data set)"
      ],
      "metadata": {
        "id": "aDvHaIk2wZIP"
      },
      "id": "aDvHaIk2wZIP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2797639-259f-4802-a2a0-815e4abc7846",
      "metadata": {
        "id": "e2797639-259f-4802-a2a0-815e4abc7846",
        "outputId": "007760cb-f159-4c64-a65a-1327a7b9d185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Loading Final Test Set ---\n",
            "Successfully loaded 9264 records from the test set.\n",
            "\n",
            "--- Applying Rule-Based Filter to Test Set ---\n",
            "Pre-classification of test set complete. Value counts:\n",
            "sampling_type\n",
            "Clinical      3424\n",
            "Monitoring    3381\n",
            "Unknown       2459\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Performing Targeted Sampling to Create Final Test Annotation Set ---\n",
            "Sampling 900 records from the 'Clinical' pool...\n",
            "Sampling 100 records from the 'Non-Clinical' pool...\n",
            "\n",
            "Created final enriched test annotation set with 1000 records.\n",
            "\n",
            "Successfully created 'Final_Evaluation_Sample_For_Dr_Poljak.xlsx'.\n",
            "This file is ready for final expert annotation.\n"
          ]
        }
      ],
      "source": [
        "# Prepare 1000 data for test\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# --- Configuration for Test Set Generation ---\n",
        "# This is the untouched test set (~9,600 records) created earlier.\n",
        "TEST_SET_FILE = '/Users/zimoyang/Documents/swine_project/data/final_test_set.csv'\n",
        "TEXT_COLUMN = 'HISTORY'\n",
        "ID_COLUMN = 'U_SUBMISSIONID'\n",
        "DATE_COLUMN = 'CREATEDT'\n",
        "\n",
        "# The desired size for the final annotation sample.\n",
        "FINAL_TEST_ANNOTATION_SIZE = 1000\n",
        "\n",
        "# --- Load the untouched test set ---\n",
        "print(\"--- Loading Final Test Set ---\")\n",
        "try:\n",
        "    df_test_final = pd.read_csv(TEST_SET_FILE)\n",
        "    print(f\"Successfully loaded {len(df_test_final)} records from the test set.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: The file '{TEST_SET_FILE}' was not found. Please ensure it has been created.\")\n",
        "    df_test_final = pd.DataFrame()\n",
        "\n",
        "if not df_test_final.empty:\n",
        "    # --- Apply the same rule-based filter to the Test Set ---\n",
        "    print(\"\\n--- Applying Rule-Based Filter to Test Set ---\")\n",
        "\n",
        "    # Re-using the same classification function for consistency\n",
        "    df_test_final['sampling_type'] = df_test_final[TEXT_COLUMN].apply(classify_text_for_sampling)\n",
        "\n",
        "    print(\"Pre-classification of test set complete. Value counts:\")\n",
        "    print(df_test_final['sampling_type'].value_counts())\n",
        "\n",
        "    # --- Perform Targeted Sampling on the Test Set ---\n",
        "    print(\"\\n--- Performing Targeted Sampling to Create Final Test Annotation Set ---\")\n",
        "\n",
        "    # We use the same 90% clinical / 10% non-clinical ratio\n",
        "    clinical_pct = 0.90\n",
        "    num_clinical_to_sample = int(FINAL_TEST_ANNOTATION_SIZE * clinical_pct)\n",
        "    num_non_clinical_to_sample = FINAL_TEST_ANNOTATION_SIZE - num_clinical_to_sample\n",
        "\n",
        "    # Create pools of records from the test set\n",
        "    clinical_pool_test = df_test_final[df_test_final['sampling_type'] == 'Clinical']\n",
        "    non_clinical_pool_test = df_test_final[df_test_final['sampling_type'] != 'Clinical']\n",
        "\n",
        "    print(f\"Sampling {num_clinical_to_sample} records from the 'Clinical' pool...\")\n",
        "    clinical_sample_test = clinical_pool_test.sample(n=min(num_clinical_to_sample, len(clinical_pool_test)), random_state=42)\n",
        "\n",
        "    print(f\"Sampling {num_non_clinical_to_sample} records from the 'Non-Clinical' pool...\")\n",
        "    non_clinical_sample_test = non_clinical_pool_test.sample(n=min(num_non_clinical_to_sample, len(non_clinical_pool_test)), random_state=42)\n",
        "\n",
        "    # Combine and shuffle the samples\n",
        "    final_test_annotation_sample = pd.concat([clinical_sample_test, non_clinical_sample_test])\n",
        "    final_test_annotation_sample = final_test_annotation_sample.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    # --- Prepare and Save the Final Annotation File ---\n",
        "    print(f\"\\nCreated final enriched test annotation set with {len(final_test_annotation_sample)} records.\")\n",
        "\n",
        "    # Define the final ICD-11 labels for the columns\n",
        "    final_icd11_labels = [\n",
        "    '[01] Certain infectious or parasitic diseases',\n",
        "    '[08] Diseases of the nervous system',\n",
        "    '[12] Diseases of the respiratory system',\n",
        "    '[13] Diseases of the digestive system',\n",
        "    '[14] Diseases of the skin',\n",
        "    '[15] Diseases of the musculoskeletal system or connective tissue',\n",
        "    '[18] Pregnancy, childbirth or the puerperium',\n",
        "    '[19] Certain conditions originating in the perinatal period',\n",
        "    'Monitoring',\n",
        "    'Unknown',\n",
        "    'Symptoms not classified elsewhere'\n",
        "    ]\n",
        "\n",
        "    # Create the wide-format DataFrame for annotation\n",
        "    columns_to_include = [ID_COLUMN, DATE_COLUMN, TEXT_COLUMN]\n",
        "    df_for_final_annotation = final_test_annotation_sample[columns_to_include].copy()\n",
        "\n",
        "    for label in final_icd11_labels:\n",
        "        df_for_final_annotation[label] = ''\n",
        "\n",
        "    # Save to a new Excel file\n",
        "    output_filename_excel = 'Final_Evaluation_Sample_For_Dr_Poljak.xlsx'\n",
        "    df_for_final_annotation.to_excel(output_filename_excel, index=False)\n",
        "\n",
        "    print(f\"\\nSuccessfully created '{output_filename_excel}'.\")\n",
        "    print(\"This file is ready for final expert annotation.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "896556c7-17ce-40ae-a8b7-a823cdea4ce4",
      "metadata": {
        "id": "896556c7-17ce-40ae-a8b7-a823cdea4ce4",
        "outputId": "f12144bb-9978-4b02-d435-585873ed5237"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Preprocessing for Final Test Set ---\n",
            "Successfully loaded spaCy model: en_core_web_md\n",
            "Loading data from '/Users/zimoyang/Documents/swine_project/data/Final_Evaluation_Sample_For_Dr_Poljak.xlsx'...\n",
            "Starting preprocessing for 1000 test records...\n",
            "Starting preprocessing pipeline...\n",
            "Cleaning text in column 'HISTORY' for 1000 records...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Records: 100%|████████████████| 1000/1000 [00:00<00:00, 84839.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying simplified rule-based classification...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Records: 100%|███████████████| 1000/1000 [00:00<00:00, 590331.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Anonymizing text for ML...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Records: 100%|██████████████████| 1000/1000 [00:04<00:00, 203.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing target labels for auxiliary ML classifiers...\n",
            "Preprocessing pipeline completed.\n",
            "\n",
            "Preprocessing complete. Took 4.93 seconds.\n",
            "Successfully saved final processed data to '/Users/zimoyang/Documents/swine_project/data/final_test_set_processed.csv'.\n",
            "\n",
            "--- Sample of Final Output DataFrame ---\n",
            "                              anonymized_text_for_ml  \\\n",
            "0  pigs falling back in nursing prev dx of swine ...   \n",
            "1  porcine feces for rotavirus sequencing group c...   \n",
            "2                                       feed samples   \n",
            "3  cough throughout barn suspect influenza but ha...   \n",
            "4  swelling in joints difficulty walking can star...   \n",
            "\n",
            "   [01] Certain infectious or parasitic diseases  \\\n",
            "0                                            NaN   \n",
            "1                                            NaN   \n",
            "2                                            NaN   \n",
            "3                                            NaN   \n",
            "4                                            NaN   \n",
            "\n",
            "   [08] Diseases of the nervous system  \\\n",
            "0                                  NaN   \n",
            "1                                  NaN   \n",
            "2                                  NaN   \n",
            "3                                  NaN   \n",
            "4                                  NaN   \n",
            "\n",
            "   [12] Diseases of the respiratory system  \\\n",
            "0                                      NaN   \n",
            "1                                      NaN   \n",
            "2                                      NaN   \n",
            "3                                      NaN   \n",
            "4                                      NaN   \n",
            "\n",
            "   [13] Diseases of the digestive system  [14] Diseases of the skin  \\\n",
            "0                                    NaN                        NaN   \n",
            "1                                    NaN                        NaN   \n",
            "2                                    NaN                        NaN   \n",
            "3                                    NaN                        NaN   \n",
            "4                                    NaN                        NaN   \n",
            "\n",
            "   [15] Diseases of the musculoskeletal system or connective tissue  \\\n",
            "0                                                NaN                  \n",
            "1                                                NaN                  \n",
            "2                                                NaN                  \n",
            "3                                                NaN                  \n",
            "4                                                NaN                  \n",
            "\n",
            "   [18] Pregnancy, childbirth or the puerperium  \\\n",
            "0                                           NaN   \n",
            "1                                           NaN   \n",
            "2                                           NaN   \n",
            "3                                           NaN   \n",
            "4                                           NaN   \n",
            "\n",
            "   [19] Certain conditions originating in the perinatal period  Monitoring  \\\n",
            "0                                                NaN                   NaN   \n",
            "1                                                NaN                   NaN   \n",
            "2                                                NaN                   NaN   \n",
            "3                                                NaN                   NaN   \n",
            "4                                                NaN                   NaN   \n",
            "\n",
            "   Unknown  Symptoms not classified elsewhere  \\\n",
            "0      NaN                                NaN   \n",
            "1      NaN                                NaN   \n",
            "2      NaN                                NaN   \n",
            "3      NaN                                NaN   \n",
            "4      NaN                                NaN   \n",
            "\n",
            "                                        cleaned_text rule_based_note_type  \\\n",
            "0  pigs falling back in nursing prev dx of swine ...          normal_rule   \n",
            "1  porcine feces for rotavirus sequencing group c...          normal_rule   \n",
            "2                                       feed samples          normal_rule   \n",
            "3  cough throughout barn suspect influenza but ha...          normal_rule   \n",
            "4  swelling in joints difficulty walking can star...          normal_rule   \n",
            "\n",
            "   target_ml_diagnostic  target_ml_unknown  is_normal_for_icd  \n",
            "0                     0                  0               True  \n",
            "1                     0                  0               True  \n",
            "2                     0                  0               True  \n",
            "3                     0                  0               True  \n",
            "4                     0                  0               True  \n"
          ]
        }
      ],
      "source": [
        "# Preprocess the 1000 test data\n",
        "import pandas as pd\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Initialize tqdm for pandas ---\n",
        "tqdm.pandas(desc=\"Processing Records\")\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "# INPUT: The annotated Excel file for the test set\n",
        "INPUT_TEST_FILE = '/Users/zimoyang/Documents/swine_project/data/Final_Evaluation_Sample_For_Dr_Poljak.xlsx'\n",
        "\n",
        "# OUTPUT: The final, processed test file ready for model evaluation\n",
        "OUTPUT_PROCESSED_TEST_FILE = '/Users/zimoyang/Documents/swine_project/data/final_test_set_processed.csv'\n",
        "\n",
        "# The column with the clinical text to be anonymized\n",
        "TEXT_COLUMN = 'HISTORY'\n",
        "\n",
        "# --- Prerequisite ---\n",
        "# This script assumes 'load_nlp_model()' and 'run_preprocessing_pipeline()' are defined.\n",
        "\n",
        "# --- 2. Load and Process the Test Data ---\n",
        "print(\"--- Starting Preprocessing for Final Test Set ---\")\n",
        "\n",
        "# Load the NLP model once\n",
        "nlp_model_global = load_nlp_model()\n",
        "\n",
        "if nlp_model_global:\n",
        "    print(f\"Loading data from '{INPUT_TEST_FILE}'...\")\n",
        "    try:\n",
        "        df_to_process = pd.read_excel(INPUT_TEST_FILE)\n",
        "\n",
        "        print(f\"Starting preprocessing for {len(df_to_process)} test records...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # This function creates the 'anonymized_text_for_ml' column\n",
        "        df_processed = run_preprocessing_pipeline(df_to_process, TEXT_COLUMN, nlp_model_global)\n",
        "\n",
        "        end_time = time.time()\n",
        "        duration = end_time - start_time\n",
        "        print(f\"\\nPreprocessing complete. Took {duration:.2f} seconds.\")\n",
        "\n",
        "        # --- THIS IS THE MODIFIED PART ---\n",
        "\n",
        "        # 1. Get the list of all label columns from the processed dataframe\n",
        "        # (This assumes label columns are the only ones left besides ID, text, etc.)\n",
        "        id_and_text_cols = ['U_SUBMISSIONID', 'CREATEDT', 'HISTORY', 'anonymized_text_for_ml']\n",
        "        label_columns = [col for col in df_processed.columns if col not in id_and_text_cols]\n",
        "\n",
        "        # 2. Define the exact columns you want to save\n",
        "        columns_to_save = ['anonymized_text_for_ml'] + label_columns\n",
        "\n",
        "        # 3. Create the final, clean dataframe\n",
        "        df_final_output = df_processed[columns_to_save]\n",
        "\n",
        "        # 4. Save the clean dataframe\n",
        "        df_final_output.to_csv(OUTPUT_PROCESSED_TEST_FILE, index=False)\n",
        "        print(f\"Successfully saved final processed data to '{OUTPUT_PROCESSED_TEST_FILE}'.\")\n",
        "\n",
        "        print(\"\\n--- Sample of Final Output DataFrame ---\")\n",
        "        print(df_final_output.head())\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file not found at '{INPUT_TEST_FILE}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "else:\n",
        "    print(\"Skipping preprocessing because NLP model could not be loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4df59268-5d2f-4d16-a43b-605ddc3a530b",
      "metadata": {
        "id": "4df59268-5d2f-4d16-a43b-605ddc3a530b",
        "outputId": "30b7aca8-2f6e-4c7b-fd5a-3e8e403a325d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded '/Users/zimoyang/Documents/swine_project/data/final_test_set_processed.csv'. Found 1000 records.\n",
            "\n",
            "Columns successfully dropped.\n",
            "Cleaned data has been successfully saved to: '/Users/zimoyang/Documents/swine_project/data/final_test_set_cleaned.csv'\n",
            "\n",
            "Remaining columns in the new file:\n",
            "['anonymized_text_for_ml', '[01] Certain infectious or parasitic diseases', '[08] Diseases of the nervous system', '[12] Diseases of the respiratory system', '[13] Diseases of the digestive system', '[14] Diseases of the skin', '[15] Diseases of the musculoskeletal system or connective tissue', '[18] Pregnancy, childbirth or the puerperium', '[19] Certain conditions originating in the perinatal period', 'Monitoring', 'Unknown', 'Symptoms not classified elsewhere']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Define the file paths\n",
        "input_file_path = \"/Users/zimoyang/Documents/swine_project/data/final_test_set_processed.csv\"\n",
        "# We'll save the cleaned data to a new file to avoid overwriting the original\n",
        "output_file_path = \"/Users/zimoyang/Documents/swine_project/data/final_test_set_cleaned.csv\"\n",
        "\n",
        "# 2. Load the CSV into a pandas DataFrame\n",
        "try:\n",
        "    df_processed = pd.read_csv(input_file_path)\n",
        "    print(f\"Successfully loaded '{input_file_path}'. Found {len(df_processed)} records.\")\n",
        "\n",
        "    # 3. Define the list of columns you want to delete\n",
        "    columns_to_drop = [\n",
        "        'cleaned_text',\n",
        "        'rule_based_note_type',\n",
        "        'target_ml_diagnostic',\n",
        "        'target_ml_unknown',\n",
        "        'is_normal_for_icd'\n",
        "    ]\n",
        "\n",
        "    # 4. Drop the columns from the DataFrame\n",
        "    # The errors='ignore' argument prevents an error if a column is not found\n",
        "    original_columns = df_processed.columns.tolist()\n",
        "    df_cleaned = df_processed.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "    print(\"\\nColumns successfully dropped.\")\n",
        "\n",
        "    # 5. Save the cleaned DataFrame to the new file\n",
        "    # Use index=False to prevent writing the DataFrame index as an extra column\n",
        "    df_cleaned.to_csv(output_file_path, index=False)\n",
        "\n",
        "    print(f\"Cleaned data has been successfully saved to: '{output_file_path}'\")\n",
        "    print(\"\\nRemaining columns in the new file:\")\n",
        "    print(df_cleaned.columns.tolist())\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file was not found at the specified path: {input_file_path}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "txDHDExCtKv7"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}